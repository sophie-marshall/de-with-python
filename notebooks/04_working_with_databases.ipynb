{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting and Extracting Relational Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- create a new table\n",
    "CREATE TABLE users (\n",
    "    id INT,\n",
    "    name VARCHAR(256), \n",
    "    street VARCHAR(256),\n",
    "    city VARCHAR(256),\n",
    "    zip VARCHAR(9)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# set connection string \n",
    "conn_string = \"dbname='de-with-python' host='localhost'\"\n",
    "\n",
    "# creat a connection \n",
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "# create a cursor \n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a query \n",
    "query = \"\"\"\n",
    "insert into users (id,name,street,city,zip)\n",
    "    values(%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "# supply data\n",
    "data = (1,'Big Bird','Sesame Street','Fakeville','12345')\n",
    "\n",
    "# preview what will be sent to the database \n",
    "cur.execute(query, data)\n",
    "\n",
    "# commit to db \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker \n",
    "\n",
    "# instantiate a faker, list to hold data, and id object\n",
    "faker = Faker()\n",
    "data = []\n",
    "i = 2\n",
    "\n",
    "# fill in and udpate values \n",
    "for r in range(1000):\n",
    "    data.append((i, faker.name(), faker.street_address(), faker.city(), faker.zipcode()))\n",
    "    i += 1\n",
    "\n",
    "# convert to tuple for db upsertion \n",
    "db_tuple = tuple(data)\n",
    "\n",
    "# execute the query for the items in the tuple\n",
    "cur.executemany(query, db_tuple)\n",
    "\n",
    "# commit the transaction \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query \n",
    "query = \"select * from users\"\n",
    "\n",
    "# submit query \n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# grab a single record \n",
    "data = cur.fetchone()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1001\n",
      "Current Row: 1\n"
     ]
    }
   ],
   "source": [
    "# print number of records and current row number\n",
    "print(f\"Number of rows: {cur.rowcount}\")\n",
    "print(f\"Current Row: {cur.rownumber}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv file\n",
    "f = open(\"../data/from_postgres.csv\", \"w\")\n",
    "\n",
    "# copy the results from the database into a csv file\n",
    "cur.copy_to(f, \"users\", sep=\",\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/l43s9_mn6hzgc7hv_3y336hr0000gs/T/ipykernel_16044/1888224397.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"select * from users\", conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_sql(\"select * from users\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Big Bird</td>\n",
       "      <td>Sesame Street</td>\n",
       "      <td>Fakeville</td>\n",
       "      <td>12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Misty Smith</td>\n",
       "      <td>66282 Christopher Flats Apt. 341</td>\n",
       "      <td>Masseyland</td>\n",
       "      <td>63835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jason Miller</td>\n",
       "      <td>49331 Bruce Views</td>\n",
       "      <td>East Joshua</td>\n",
       "      <td>69414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Regina Maynard</td>\n",
       "      <td>103 Angel Roads Suite 570</td>\n",
       "      <td>Port Jasonland</td>\n",
       "      <td>21975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alicia Conway</td>\n",
       "      <td>44755 Ryan Valley Apt. 606</td>\n",
       "      <td>Allenchester</td>\n",
       "      <td>39890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Valerie Scott</td>\n",
       "      <td>6184 Davis Manor Suite 930</td>\n",
       "      <td>South Joyberg</td>\n",
       "      <td>97295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Philip Lowe</td>\n",
       "      <td>4115 Justin Spur</td>\n",
       "      <td>Stevenhaven</td>\n",
       "      <td>25156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Duane Dillon</td>\n",
       "      <td>18729 Martinez Trail Suite 249</td>\n",
       "      <td>Shawnabury</td>\n",
       "      <td>87659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>Megan Freeman</td>\n",
       "      <td>8354 Harris Plaza</td>\n",
       "      <td>East Daisy</td>\n",
       "      <td>45106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1001</td>\n",
       "      <td>Tami Scott</td>\n",
       "      <td>4167 Melanie Glen Suite 900</td>\n",
       "      <td>Murphyshire</td>\n",
       "      <td>40385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            name                            street            city  \\\n",
       "0        1        Big Bird                     Sesame Street       Fakeville   \n",
       "1        2     Misty Smith  66282 Christopher Flats Apt. 341      Masseyland   \n",
       "2        3    Jason Miller                 49331 Bruce Views     East Joshua   \n",
       "3        4  Regina Maynard         103 Angel Roads Suite 570  Port Jasonland   \n",
       "4        5   Alicia Conway        44755 Ryan Valley Apt. 606    Allenchester   \n",
       "...    ...             ...                               ...             ...   \n",
       "996    997   Valerie Scott        6184 Davis Manor Suite 930   South Joyberg   \n",
       "997    998     Philip Lowe                  4115 Justin Spur     Stevenhaven   \n",
       "998    999    Duane Dillon    18729 Martinez Trail Suite 249      Shawnabury   \n",
       "999   1000   Megan Freeman                 8354 Harris Plaza      East Daisy   \n",
       "1000  1001      Tami Scott       4167 Melanie Glen Suite 900     Murphyshire   \n",
       "\n",
       "        zip  \n",
       "0     12345  \n",
       "1     63835  \n",
       "2     69414  \n",
       "3     21975  \n",
       "4     39890  \n",
       "...     ...  \n",
       "996   97295  \n",
       "997   25156  \n",
       "998   87659  \n",
       "999   45106  \n",
       "1000  40385  \n",
       "\n",
       "[1001 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting and Extracting NoSQL Database Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/l43s9_mn6hzgc7hv_3y336hr0000gs/T/ipykernel_16044/1685619415.py:7: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch({\"https://localhost:9200\"},\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'srmarshall-mac.local', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'sKoTSYCWTkuz0Fhd8DCQLw', 'version': {'number': '8.14.3', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'd55f984299e0e88dee72ebd8255f7ff130859ad0', 'build_date': '2024-07-07T22:04:49.882652950Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from faker import Faker \n",
    "import os\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# create an elastic search connection \n",
    "es = Elasticsearch({\"https://localhost:9200\"}, \n",
    "                   ssl_assert_fingerprint=\"e2c544e24108b1ee5ef4150d7e3af9aa6eb0cfc4222bbe749add1c1f8715a593\",\n",
    "                   http_auth=(\"elastic\", \"u8Xsv+o2ZSDT*H+UQFC3\"))\n",
    "\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srmarshall/miniconda3/envs/etl/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n"
     ]
    }
   ],
   "source": [
    "# add data\n",
    "doc = {\n",
    "    \"name\": faker.name(), \n",
    "    \"street\": faker.street_address(),\n",
    "    \"city\": faker.city(),\n",
    "    \"zip\": faker.zipcode(),\n",
    "}\n",
    "\n",
    "res = es.index(index=\"users\", body=doc)\n",
    "\n",
    "print(res[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers \n",
    "\n",
    "# prepare actions for elsaticsearch helper\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": \"users\", \n",
    "        \"_source\": {\n",
    "            \"name\": faker.name(),\n",
    "            \"street\": faker.street_address(),\n",
    "            \"city\": faker.city(),\n",
    "            \"zip\":faker.zipcode()\n",
    "        }\n",
    "    }\n",
    "    for x in range (998)\n",
    "]\n",
    "\n",
    "# insert using bulk \n",
    "res = helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 2, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 999, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'users', '_id': 'pbutp5ABPMaFYuJ5P3rs', '_score': 1.0, '_source': {'name': 'Donna Smith', 'street': '0216 Myers Stravenue Apt. 961', 'city': 'North Scott', 'zip': '65089'}}, {'_index': 'users', '_id': 'pru2p5ABPMaFYuJ52nqS', '_score': 1.0, '_source': {'name': 'Erik Brooks', 'street': '18719 Kayla Mountains', 'city': 'New Geraldland', 'zip': '01093'}}, {'_index': 'users', '_id': 'p7u2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Zachary Sanchez', 'street': '2048 Kent Bridge', 'city': 'Brandonhaven', 'zip': '67417'}}, {'_index': 'users', '_id': 'qLu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Glen Yates', 'street': '1324 Mclaughlin Stream Apt. 671', 'city': 'Donaldsonland', 'zip': '48112'}}, {'_index': 'users', '_id': 'qbu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Shannon Bennett', 'street': '083 Jennifer Garden Suite 313', 'city': 'Port Melindastad', 'zip': '66440'}}, {'_index': 'users', '_id': 'qru2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Christian Flores', 'street': '670 Bethany Centers Suite 114', 'city': 'Lake Angelastad', 'zip': '42955'}}, {'_index': 'users', '_id': 'q7u2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Daniel Cobb', 'street': '5752 Alexandra Common', 'city': 'Brianburgh', 'zip': '12600'}}, {'_index': 'users', '_id': 'rLu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Daniel Webb', 'street': '70063 Johnson Dale', 'city': 'Sharonbury', 'zip': '24312'}}, {'_index': 'users', '_id': 'rbu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Damon Vega', 'street': '1518 Thomas Corners', 'city': 'Saraberg', 'zip': '46996'}}, {'_index': 'users', '_id': 'rru2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Jonathan Martin', 'street': '1900 West Knoll Suite 796', 'city': 'West Rickyhaven', 'zip': '40855'}}]}}\n"
     ]
    }
   ],
   "source": [
    "# query index\n",
    "doc = {\n",
    "    \"query\": {\"match_all\": {}}\n",
    "}\n",
    "\n",
    "res = es.search(index=\"users\", body=doc)\n",
    "\n",
    "# preview response\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_index': 'users', '_id': 'pbutp5ABPMaFYuJ5P3rs', '_score': 1.0, '_source': {'name': 'Donna Smith', 'street': '0216 Myers Stravenue Apt. 961', 'city': 'North Scott', 'zip': '65089'}}, {'_index': 'users', '_id': 'pru2p5ABPMaFYuJ52nqS', '_score': 1.0, '_source': {'name': 'Erik Brooks', 'street': '18719 Kayla Mountains', 'city': 'New Geraldland', 'zip': '01093'}}, {'_index': 'users', '_id': 'p7u2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Zachary Sanchez', 'street': '2048 Kent Bridge', 'city': 'Brandonhaven', 'zip': '67417'}}, {'_index': 'users', '_id': 'qLu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Glen Yates', 'street': '1324 Mclaughlin Stream Apt. 671', 'city': 'Donaldsonland', 'zip': '48112'}}, {'_index': 'users', '_id': 'qbu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Shannon Bennett', 'street': '083 Jennifer Garden Suite 313', 'city': 'Port Melindastad', 'zip': '66440'}}, {'_index': 'users', '_id': 'qru2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Christian Flores', 'street': '670 Bethany Centers Suite 114', 'city': 'Lake Angelastad', 'zip': '42955'}}, {'_index': 'users', '_id': 'q7u2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Daniel Cobb', 'street': '5752 Alexandra Common', 'city': 'Brianburgh', 'zip': '12600'}}, {'_index': 'users', '_id': 'rLu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Daniel Webb', 'street': '70063 Johnson Dale', 'city': 'Sharonbury', 'zip': '24312'}}, {'_index': 'users', '_id': 'rbu2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Damon Vega', 'street': '1518 Thomas Corners', 'city': 'Saraberg', 'zip': '46996'}}, {'_index': 'users', '_id': 'rru2p5ABPMaFYuJ52nqT', '_score': 1.0, '_source': {'name': 'Jonathan Martin', 'street': '1900 West Knoll Suite 796', 'city': 'West Rickyhaven', 'zip': '40855'}}]\n"
     ]
    }
   ],
   "source": [
    "print(res[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Donna Smith', 'street': '0216 Myers Stravenue Apt. 961', 'city': 'North Scott', 'zip': '65089'}\n",
      "{'name': 'Erik Brooks', 'street': '18719 Kayla Mountains', 'city': 'New Geraldland', 'zip': '01093'}\n",
      "{'name': 'Zachary Sanchez', 'street': '2048 Kent Bridge', 'city': 'Brandonhaven', 'zip': '67417'}\n",
      "{'name': 'Glen Yates', 'street': '1324 Mclaughlin Stream Apt. 671', 'city': 'Donaldsonland', 'zip': '48112'}\n",
      "{'name': 'Shannon Bennett', 'street': '083 Jennifer Garden Suite 313', 'city': 'Port Melindastad', 'zip': '66440'}\n",
      "{'name': 'Christian Flores', 'street': '670 Bethany Centers Suite 114', 'city': 'Lake Angelastad', 'zip': '42955'}\n",
      "{'name': 'Daniel Cobb', 'street': '5752 Alexandra Common', 'city': 'Brianburgh', 'zip': '12600'}\n",
      "{'name': 'Daniel Webb', 'street': '70063 Johnson Dale', 'city': 'Sharonbury', 'zip': '24312'}\n",
      "{'name': 'Damon Vega', 'street': '1518 Thomas Corners', 'city': 'Saraberg', 'zip': '46996'}\n",
      "{'name': 'Jonathan Martin', 'street': '1900 West Knoll Suite 796', 'city': 'West Rickyhaven', 'zip': '40855'}\n"
     ]
    }
   ],
   "source": [
    "# preview items \n",
    "for doc in res[\"hits\"][\"hits\"]:\n",
    "    print(doc[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to a df \n",
    "df = pd.json_normalize(res[\"hits\"][\"hits\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Donna Smith', 'street': '0216 Myers Stravenue Apt. 961', 'city': 'North Scott', 'zip': '65089'}\n"
     ]
    }
   ],
   "source": [
    "# search for a specific entry uisng the match attribue and passing the nested attribute you'd like \n",
    "doc = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"name\": \"Donna Smith\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=\"users\", body=doc)\n",
    "\n",
    "print(res[\"hits\"][\"hits\"][0][\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Damon Vega', 'street': '1518 Thomas Corners', 'city': 'Saraberg', 'zip': '46996'}\n"
     ]
    }
   ],
   "source": [
    "doc = {\n",
    "    \"query\":{\n",
    "        \"match\": {\n",
    "            \"city\": \"Saraberg\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=\"users\", body=doc)\n",
    "\n",
    "for item in res[\"hits\"][\"hits\"]:\n",
    "    print(item[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found!\n"
     ]
    }
   ],
   "source": [
    "# boolean queries \n",
    "doc = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": { \"match\" : {\"city\": \"Saraberg\"}}, \n",
    "            \"filter\": {\"term\": {\"zip\": \"53217\"}}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = es.search(index=\"users\", body=doc)\n",
    "\n",
    "if len(res[\"hits\"][\"hits\"]) == 0:\n",
    "    print(\"No results found!\") ## SM: this is expected behavior for the fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipelines in Apache Airflow \n",
    "\n",
    "Build on existing Airflow knowledge to extract data from PostgreSQL and write it to an elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from elasticsearch import Elasticsearch\n",
    "import os\n",
    "\n",
    "\n",
    "# define helper functions\n",
    "def query_pg(db_name, host, query, output_filepath):\n",
    "    conn_string = f\"dbname={db_name} host={host}\"\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df.to_csv(output_filepath)\n",
    "    print(\"---------- Postgres Data Saved ----------\")\n",
    "\n",
    "\n",
    "def insert_es(host, ssl_assert_fingerprint, username, password, input_filepath):\n",
    "    # establish an Elasticsearch connection\n",
    "    es = Elasticsearch(\n",
    "        {host},\n",
    "        ssl_assert_fingerprint=ssl_assert_fingerprint,\n",
    "        http_auth=(username, password),\n",
    "    )\n",
    "    df = pd.read_csv(input_filepath)\n",
    "    for i, r in df.iterrows():\n",
    "        doc = r.to_json()\n",
    "        res = es.index(index=\"frompostgres\", body=doc)\n",
    "        print(res)\n",
    "\n",
    "\n",
    "# set defaults\n",
    "default_args = {\n",
    "    \"owner\": \"srmarshall\",\n",
    "    \"start_date\": dt.datetime(2024, 7, 12),\n",
    "    \"retries\": 1,\n",
    "    \"retry_delay\": timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "# create dag\n",
    "with DAG(\n",
    "    \"pg_to_elasticsearch_dag\",\n",
    "    default_args=default_args,\n",
    "    schedule_interval=timedelta(minutes=5),\n",
    ") as dag:\n",
    "    getData = PythonOperator(\n",
    "        task_id=\"QueryPostgreSQL\",\n",
    "        python_callable=query_pg,\n",
    "        op_kwargs={\n",
    "            \"db_name\": \"de-with-python\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"query\": \"select name, city, from users\",\n",
    "            \"output_filepath\": \"/Users/srmarshall/Desktop/code/personal/de-with-python/data/pg_csv.csv\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    insertData = PythonOperator(\n",
    "        task_id=\"InsertElasticSearch\",\n",
    "        python_callable=insert_es,\n",
    "        op_kwargs={\n",
    "            \"host\": \"https://localhost:9200\",\n",
    "            \"ssl_assert_fingerprint\": os.getenv(\"ES_FINGERPRINT\"),\n",
    "            \"username\": \"elasticsearch\",\n",
    "            \"password\": os.getenv(\"ES_PASSWORD\"),\n",
    "            \"input_filepath\": \"/Users/srmarshall/Desktop/code/personal/de-with-python/data/pg_csv.csv\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    getData >> insertData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
